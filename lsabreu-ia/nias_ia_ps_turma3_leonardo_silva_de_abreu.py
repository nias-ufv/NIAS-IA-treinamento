# -*- coding: utf-8 -*-
"""NIAS - IA - PS - TURMA3 - LEONARDO SILVA DE ABREU

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ecp1Mee_2OdF1084UMw45KvakxyACJMo
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import train_test_split  # Adicione esta importação
# %pip install scikit-optimize


#baseline 76.555%
#modelo 3 76.794%

#%% abrir o datase de treino e teste

train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')

#%% pre-processamento dos dados

#descrição estátistica das features núméricas

print("\n \n Informações de TRAIN: ⬇️ \n \n", train.info())
print("\n \n Informações de TEST:\n \n ⬇️", test.info())

#verificar valores nulos ou NAN
print("\n \n Valores nulos em TRAIN: \n", train.isnull().sum())
print ("\n")
print("\n \n Valores nulos em TEST: \n", test.isnull().sum())

#mapear as colunas
col = pd.Series(list(train.columns))

X_train = train.drop(['PassengerId', 'Survived'], axis = 1)

X_test = test.drop(['PassengerId'], axis = 1)

print ("\n", X_train.columns)
print ("\n", X_test.columns)

#%%#criar feature

def criar_features(X):
  subs = {'female':1, 'male':0}
  X['mulher'] = X['Sex'].replace(subs)

  X['Fare'] = X['Fare'].fillna(X['Fare'].mean())

  X['Age'] = X['Age'].fillna(X['Age'].mean())

  X['Embarked'] = X['Embarked'].fillna('S')

  subs = {'S':1, 'C':2, 'Q':3}
  X['porto'] = X['Embarked'].replace(subs)

  X['crianca'] = 1
  X['crianca'] = np.where(X['Age'] < 12, 1, 0)

  # Extrair título do nome
  X['titulo'] = X['Name'].str.extract(' ([A-Za-z]+)\.', expand=False)
  X['titulo'] = X['titulo'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')
  X['titulo'] = X['titulo'].replace('Mlle', 'Miss')
  X['titulo'] = X['titulo'].replace('Ms', 'Miss')
  X['titulo'] = X['titulo'].replace('Mme', 'Mrs')

  # Tamanho da família
  X['familia_size'] = X['SibSp'] + X['Parch'] + 1

  # Cabine
  X['cabine_letra'] = X['Cabin'].str[0]
  X['cabine_letra'] = X['cabine_letra'].fillna('N')

  # Categorização de Fare
  X['fare_cat'] = pd.qcut(X['Fare'], 4, labels=[1, 2, 3, 4])
  X['fare_cat'] = X['fare_cat'].astype(int)

  # Novas features:
  X['sozinho'] = ((X['SibSp'] + X['Parch']) == 0).astype(int)
  X['familia_pequena'] = ((X['SibSp'] + X['Parch']) > 0) & ((X['SibSp'] + X['Parch']) <= 3).astype(int)
  X['familia_grande'] = ((X['SibSp'] + X['Parch']) > 3).astype(int)

  # Interação entre classe e tarifa
  X['classe_fare'] = X['Pclass'] * X['Fare']

  # Idade categorizada
  X['idade_cat'] = pd.cut(X['Age'], bins=[0, 12, 18, 35, 60, 100],
                         labels=[1, 2, 3, 4, 5]).astype('category').cat.codes

  return X

# Define X_train and X_test before calling the function
X_train = train.drop(['PassengerId', 'Survived'], axis = 1)
X_test = test.drop(['PassengerId'], axis = 1)

X_train = criar_features(X_train)
X_test = criar_features(X_test)

#%% Selecionar as features

features = ['Pclass', 'Age', 'SibSp', 'Embarked',
       'Parch', 'Fare', 'mulher', 'porto', 'crianca','titulo',
            'familia_size', 'cabine_letra', 'fare_cat', 'sozinho', 'familia_pequena', 'familia_grande','classe_fare','idade_cat']

X_train = X_train[features]
X_test = X_test[features]

y_train = train['Survived']

#%% Visualização

import matplotlib.pyplot as plt

# Exclude boolean columns from plotting
columns_to_plot = [col for col in X_train.columns if X_train[col].dtype != 'bool']

for i in columns_to_plot:
    plt.hist(X_train[i])
    plt.title(i)
    plt.show()

#%% Groupy

gp = train.groupby(['Survived']).count()

#%% pivot_table

table = pd.pivot_table(train, index = ['Survived'], columns = ['Pclass'], values = 'PassengerId', aggfunc = 'count')

# Re-run the feature creation to ensure 'titulo' and 'cabine_letra' are present
X_train = train.drop(['PassengerId', 'Survived'], axis = 1)
X_test = test.drop(['PassengerId'], axis = 1)

X_train = criar_features(X_train)
X_test = criar_features(X_test)

# Now run the code for one-hot encoding and scaling
combined_data = pd.concat([X_train, X_test], ignore_index=True)

combined_data = pd.get_dummies(combined_data, columns=['titulo', 'cabine_letra'], drop_first=True)

# Drop the original non-numeric columns that were not one-hot encoded
combined_data = combined_data.drop(['Name', 'Sex', 'Ticket', 'Embarked', 'Cabin'], axis=1)


# Split back into train and test sets
X_train_encoded = combined_data.iloc[:len(X_train)]
X_test_encoded = combined_data.iloc[len(X_train):]

scaler = StandardScaler()

X_train_sc = scaler.fit_transform(X_train_encoded)
X_test_sc = scaler.transform(X_test_encoded)

# Ensure y_train has no NaNs after splitting and scaling
if y_train.isnull().any():
    mask = y_train.notnull()
    X_train_sc = X_train_sc[mask]
    y_train = y_train[mask]


print("One-hot encoding and scaling completed successfully and NaNs in y_train handled. \n")

#%% modelo e validação cruzada

#Logistic Regression
model_lr = LogisticRegression (penalty='l2', C=1)

score = cross_val_score(model_lr, X_train_sc, y_train, cv = 10)

# Certifique-se de que y_pred esteja definido para confusion_matrix

model_lr.fit(X_train_sc, y_train)
y_pred = model_lr.predict(X_train_sc)

mc = confusion_matrix(y_train, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(mc, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['Não Sobreviveu', 'Sobreviveu'],
            yticklabels=['Não Sobreviveu', 'Sobreviveu'])
plt.xlabel('Previsto')
plt.ylabel('Real')
# Calculate the mean of the scores for the title
plt.title(f'Matriz de Confusão do Modelo Logistic Regression (Acurácia: {np.mean(score):.4f})')
plt.show()

#%% Naive Bayes para Classificação

from sklearn.naive_bayes import GaussianNB

model_nb = GaussianNB()

score = cross_val_score(model_nb, X_train_sc, y_train, cv = 10)

# Certifique-se de que y_pred esteja definido para confusion_matrix

model_nb.fit(X_train_sc, y_train)
y_pred = model_nb.predict(X_train_sc)

mc = confusion_matrix(y_train, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(mc, annot=True, fmt='d', cmap='Greens', cbar=False,
            xticklabels=['Não Sobreviveu', 'Sobreviveu'],
            yticklabels=['Não Sobreviveu', 'Sobreviveu'])
plt.xlabel('Previsto')
plt.ylabel('Real')
# Calculate the mean of the scores for the title
plt.title(f'Matriz de Confusão do Modelo Naive Bayes (Acurácia: {np.mean(score):.4f})')
plt.show()

#%% KNN para classificação

from sklearn.neighbors import KNeighborsClassifier

model_knn = KNeighborsClassifier(n_neighbors= 7, p = 1, weights='uniform')

# Certifique-se de que y_pred esteja definido para confusion_matrix

model_knn.fit(X_train_sc, y_train)
y_pred = model_knn.predict(X_train_sc)

score = cross_val_score(model_knn, X_train_sc, y_train, cv = 10)
#print(np.mean(score))
#print (score)
mc = confusion_matrix(y_train, y_pred)
#print (mc)

plt.figure(figsize=(8, 6))
sns.heatmap(mc, annot=True, fmt='d', cmap='Purples', cbar=False,
            xticklabels=['Não Sobreviveu', 'Sobreviveu'],
            yticklabels=['Não Sobreviveu', 'Sobreviveu'])
plt.xlabel('Previsto')
plt.ylabel('Real')
# Calculate the mean of the scores for the title
plt.title(f'Matriz de Confusão do Modelo K — Nearest Neighbors (KNN) (Acurácia: {np.mean(score):.4f})')
plt.show()

#%% SVM para classificação
from sklearn.svm import SVC

model_svc = SVC(C = 3, kernel = 'rbf', degree = 2, gamma = 0.1)

# Certifique-se de que y_pred esteja definido para confusion_matrix

model_svc.fit(X_train_sc, y_train)
y_pred = model_svc.predict(X_train_sc)

score = cross_val_score(model_svc, X_train_sc, y_train, cv = 10)
mc = confusion_matrix(y_train, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(mc, annot=True, fmt='d', cmap='cool', cbar=False,
            xticklabels=['Não Sobreviveu', 'Sobreviveu'],
            yticklabels=['Não Sobreviveu', 'Sobreviveu'])
plt.xlabel('Previsto')
plt.ylabel('Real')
# Calculate the mean of the scores for the title
plt.title(f'Matriz de Confusão do Modelo SVM/SVC (Acurácia: {np.mean(score):.4f})')
plt.show()

#%% Decision Tree

from sklearn.tree import DecisionTreeClassifier

model_dt = DecisionTreeClassifier(criterion = 'gini', max_depth = 3, min_samples_split = 2, min_samples_leaf = 1, random_state = 0)

# Certifique-se de que y_pred esteja definido para confusion_matrix

model_dt.fit(X_train_sc, y_train)
y_pred = model_dt.predict(X_train_sc)

score = cross_val_score(model_dt, X_train_sc, y_train, cv = 10)
mc = confusion_matrix(y_train, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(mc, annot=True, fmt='d', cmap='bone', cbar=False,
            xticklabels=['Não Sobreviveu', 'Sobreviveu'],
            yticklabels=['Não Sobreviveu', 'Sobreviveu'])
plt.xlabel('Previsto')
plt.ylabel('Real')
# Calculate the mean of the scores for the title
plt.title(f'Matriz de Confusão do Modelo Decision Tree (Acurácia: {np.mean(score):.4f})')
plt.show()

#%% Random Forest

from sklearn.ensemble import RandomForestClassifier

model_rf = RandomForestClassifier(criterion = 'entropy', n_estimators = 100, max_depth = 5, min_samples_split = 2, min_samples_leaf = 1, random_state = 0)

# Certifique-se de que y_pred esteja definido para confusion_matrix

model_rf = model_rf.fit(X_train_sc, y_train)
y_pred = model_rf.predict(X_train_sc)

score = cross_val_score(model_rf, X_train_sc, y_train, cv = 10)
mc = confusion_matrix(y_train, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(mc, annot=True, fmt='d', cmap='pink', cbar=False,
            xticklabels=['Não Sobreviveu', 'Sobreviveu'],
            yticklabels=['Não Sobreviveu', 'Sobreviveu'])
plt.xlabel('Previsto')
plt.ylabel('Real')
# Calculate the mean of the scores for the title
plt.title(f'Matriz de Confusão do Modelo Random Forest (Acurácia: {np.mean(score):.4f})')
plt.show()

#%% XGBoost

from xgboost import XGBClassifier

model_xgb = XGBClassifier(max_depth = 2, learning_rate = 0.5, n_estimators = 300)

# Certifique-se de que y_pred esteja definido para confusion_matrix

model_xgb.fit(X_train_sc, y_train)
y_pred = model_xgb.predict(X_train_sc)

score = cross_val_score(model_xgb, X_train_sc, y_train, cv = 10)
mc = confusion_matrix(y_train, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(mc, annot=True, fmt='d', cmap='binary', cbar=False,
            xticklabels=['Não Sobreviveu', 'Sobreviveu'],
            yticklabels=['Não Sobreviveu', 'Sobreviveu'])
plt.xlabel('Previsto')
plt.ylabel('Real')
# Calculate the mean of the scores for the title
plt.title(f'Matriz de Confusão do Modelo XGBoost (Acurácia: {np.mean(score):.4f})')
plt.show()

"""# Otimização de hiperparâmetros"""

#%% Otimização de hiperparametros para Radom Forest

from skopt import gp_minimize

def treinar_modelo(parametros):

  model_rf = RandomForestClassifier(criterion = parametros[0], n_estimators = parametros[1], max_depth = parametros[2],
                                    min_samples_split = parametros[3], min_samples_leaf = parametros[4], random_state = 0, n_jobs = -1 )

  score = cross_val_score(model_rf, X_train_sc, y_train, cv = 10)

  mean_score = np.mean(score)

  print(np.mean(score))

  return -mean_score

parametros = [('entropy', 'gini'),
              (100, 1000),
              (3, 20),
              (2, 10),
              (1, 10)]


otimos = gp_minimize(treinar_modelo, parametros, random_state = 0, verbose = 1, n_calls = 30, n_random_starts = 10  )


print(otimos.fun, otimos.x)

#%% modelo final FR

model_rf = RandomForestClassifier(criterion = otimos.x[0], n_estimators = otimos.x[1], max_depth = otimos.x[2],
                                    min_samples_split = otimos.x[3], min_samples_leaf = otimos.x[4], random_state = 0, n_jobs = -1 )

# Certifique-se de que y_pred esteja definido para confusion_matrix

model_rf.fit(X_train_sc, y_train)
y_pred = model_rf.predict(X_train_sc)

mc = confusion_matrix(y_train, y_pred)

score = model_rf.score(X_train_sc, y_train)

plt.figure(figsize=(8, 6))
sns.heatmap(mc, annot=True, fmt='d', cmap='Reds', cbar=False,
            xticklabels=['Não Sobreviveu', 'Sobreviveu'],
            yticklabels=['Não Sobreviveu', 'Sobreviveu'])
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.title(f'Matriz de Confusão do Modelo Random Forest (Acurácia: {score:.4f})')
plt.show()

#%% Otimização de hiperparâmetros para XGBoost

from skopt import gp_minimize
from skopt.space import Real, Integer, Categorical
from xgboost import XGBClassifier

def treinar_modelo_xgb(parametros):
    # Parâmetros do XGBoost (mais relevantes para otimização)
    model_xgb = XGBClassifier(
        learning_rate=parametros[0],      # Taxa de aprendizado (eta)
        n_estimators=int(parametros[1]),  # Número de árvores
        max_depth=int(parametros[2]),     # Profundidade máxima
        min_child_weight=parametros[3],   # Peso mínimo das folhas
        subsample=parametros[4],         # Amostragem de linhas
        colsample_bytree=parametros[5],   # Amostragem de features
        gamma=parametros[6],             # Redução de loss mínima para split
        reg_alpha=parametros[7],         # Regularização L1
        reg_lambda=parametros[8],        # Regularização L2
        random_state=0,
        n_jobs=-1,
        eval_metric='logloss'            # Métrica para classificação
    )

    # Validação cruzada (10 folds)
    score = cross_val_score(model_xgb, X_train_sc, y_train, cv=10, scoring='accuracy')
    mean_score = np.mean(score)
    print(f"Acurácia média: {mean_score:.4f}")

    return -mean_score  # Minimizar o negativo da acurácia

# Espaço de busca para os hiperparâmetros

parametros_xgb = [
    Real(0.01, 0.3, prior='log-uniform'), # learning_rate
    Integer(50, 1000),                    # n_estimators
    Integer(3, 10),                       # max_depth
    Real(1, 10, prior='log-uniform'),     # min_child_weight
    Real(0.6, 1.0, prior='uniform'),      # subsample
    Real(0.6, 1.0, prior='uniform'),      # colsample_bytree
    Real(0, 0.5, prior='uniform'),        # gamma
    Real(1e-9, 10, prior='log-uniform'),     # reg_alpha (L1)
    Real(1e-9, 10, prior='log-uniform')      # reg_lambda (L2)
]

# Otimização Bayesiana
otimos_xgb = gp_minimize(
    treinar_modelo_xgb,
    parametros_xgb,
    random_state=0,
    verbose=1,
    n_calls=30,
    n_random_starts=10
)

# Resultados
print(f"Melhor acurácia: {-otimos_xgb.fun:.4f}")
print("Melhores hiperparâmetros:")
print(f"learning_rate: {otimos_xgb.x[0]}")
print(f"n_estimators: {int(otimos_xgb.x[1])}")
print(f"max_depth: {int(otimos_xgb.x[2])}")
print(f"min_child_weight: {otimos_xgb.x[3]}")
print(f"subsample: {otimos_xgb.x[4]}")
print(f"colsample_bytree: {otimos_xgb.x[5]}")
print(f"gamma: {otimos_xgb.x[6]}")
print(f"reg_alpha: {otimos_xgb.x[7]}")
print(f"reg_lambda: {otimos_xgb.x[8]}")

model_xgb = XGBClassifier(
    learning_rate=otimos_xgb.x[0],
    n_estimators=int(otimos_xgb.x[1]),
    max_depth=int(otimos_xgb.x[2]),
    min_child_weight=otimos_xgb.x[3],
    subsample=otimos_xgb.x[4],
    colsample_bytree=otimos_xgb.x[5],
    gamma=otimos_xgb.x[6],
    reg_alpha=otimos_xgb.x[7],
    reg_lambda=otimos_xgb.x[8],
    random_state=0
)
# Certifique-se de que y_pred esteja definido para confusion_matrix

model_xgb.fit(X_train_sc, y_train)
y_pred = model_xgb.predict(X_train_sc)

mc = confusion_matrix(y_train, y_pred)
score = model_xgb.score(X_train_sc, y_train)

plt.figure(figsize=(8, 6))
sns.heatmap(mc, annot=True, fmt='d', cmap='Reds', cbar=False,
            xticklabels=['Não Sobreviveu', 'Sobreviveu'],
            yticklabels=['Não Sobreviveu', 'Sobreviveu'])
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.title(f'Matriz de Confusão do Modelo XGBoost (Acurácia: {score:.4f})')
plt.show()

#%% Otimização de hiperparâmetros para SVM/SVC
from skopt import gp_minimize
from sklearn.svm import SVC

def treinar_modelo_svm(parametros):
    model_svc = SVC(
        C=parametros[0],               # Parâmetro de regularização
        kernel=parametros[1],           # Tipo de kernel ('rbf', 'poly', etc.)
        gamma=parametros[2],            # Coeficiente para kernels não lineares
        degree=int(parametros[3]),      # Grau do kernel polinomial (se aplicável)
        coef0=parametros[4],           # Termo independente em kernels polinomiais/sigmoid
        probability=True,              # Necessário para algumas métricas
        random_state=0
    )

    # Validação cruzada (10 folds)
    score = cross_val_score(model_svc, X_train_sc, y_train, cv=10, scoring='accuracy')
    mean_score = np.mean(score)
    print(f"Acurácia média: {mean_score:.4f}")

    return -mean_score  # Minimizar o negativo da acurácia

# Espaço de busca para os hiperparâmetros
parametros_svm = [
    (0.1, 10),                        # C (regularização)
    ['rbf'],                          # kernel
    (0.01, 1),                        # gamma
    (2, 3),                           # degree (apenas para 'poly')
    (0, 0.5)                          # coef0 (para 'poly' e 'sigmoid')
]

# Otimização Bayesiana
otimos_svm = gp_minimize(
    treinar_modelo_svm,
    parametros_svm,
    random_state=0,
    verbose=1,
    n_calls=30,
    n_random_starts=10
)

# Resultados
print(f"Melhor acurácia: {-otimos_svm.fun:.4f}")
print("Melhores hiperparâmetros:")
print(f"C: {otimos_svm.x[0]}")
print(f"kernel: {otimos_svm.x[1]}")
print(f"gamma: {otimos_svm.x[2]}")
print(f"degree: {int(otimos_svm.x[3])}")
print(f"coef0: {otimos_svm.x[4]}")

model_svc = SVC(
    C=otimos_svm.x[0],
    kernel=otimos_svm.x[1],
    gamma=otimos_svm.x[2],
    degree=int(otimos_svm.x[3]),
    coef0=otimos_svm.x[4],
    probability=True,
    random_state=0
)

# Certifique-se de que y_pred esteja definido para confusion_matrix

model_svc.fit(X_train_sc, y_train)
y_pred = model_svc.predict(X_train_sc)

mc = confusion_matrix(y_train, y_pred)
score = model_svc.score(X_train_sc, y_train)

plt.figure(figsize=(8, 6))
sns.heatmap(mc, annot=True, fmt='d', cmap='Reds', cbar=False,
            xticklabels=['Não Sobreviveu', 'Sobreviveu'],
            yticklabels=['Não Sobreviveu', 'Sobreviveu'])
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.title(f'Matriz de Confusão do Modelo SVM/SVC (Acurácia: {score:.4f})')
plt.show()

#%% Otimização de hiperparâmetros para Decision Tree

from skopt import gp_minimize
from sklearn.tree import DecisionTreeClassifier

def treinar_modelo_dt(parametros):
    model_dt = DecisionTreeClassifier(
        criterion=parametros[0],          # 'gini' ou 'entropy'
        max_depth=int(parametros[1]),     # Profundidade máxima
        min_samples_split=int(parametros[2]),  # Mínimo de amostras para dividir
        min_samples_leaf=int(parametros[3]),   # Mínimo de amostras por folha
        max_features=parametros[4],       # Número de features para split
        ccp_alpha=parametros[5],          # Parâmetro de poda
        random_state=0
    )

    # Validação cruzada (10 folds)
    score = cross_val_score(model_dt, X_train_sc, y_train, cv=10, scoring='accuracy')
    mean_score = np.mean(score)
    print(f"Acurácia média: {mean_score:.4f}")

    return -mean_score  # Minimizar o negativo da acurácia

# Espaço de busca para os hiperparâmetros
parametros_dt = [
    ['gini', 'entropy'],                 # criterion
    (2, 30),                             # max_depth
    (2, 20),                             # min_samples_split
    (1, 10),                             # min_samples_leaf
    ['sqrt', 'log2', None],              # max_features
    (0.0, 0.02)                          # ccp_alpha (poda)
]

# Otimização Bayesiana
otimos_dt = gp_minimize(
    treinar_modelo_dt,
    parametros_dt,
    random_state=0,
    verbose=1,
    n_calls=30,
    n_random_starts=10
)

# Resultados
print(f"Melhor acurácia: {-otimos_dt.fun:.4f}")
print("Melhores hiperparâmetros:")
print(f"criterion: {otimos_dt.x[0]}")
print(f"max_depth: {int(otimos_dt.x[1])}")
print(f"min_samples_split: {int(otimos_dt.x[2])}")
print(f"min_samples_leaf: {int(otimos_dt.x[3])}")
print(f"max_features: {otimos_dt.x[4]}")
print(f"ccp_alpha: {otimos_dt.x[5]}")

model_dt = DecisionTreeClassifier(
    criterion=otimos_dt.x[0],
    max_depth=int(otimos_dt.x[1]),
    min_samples_split=int(otimos_dt.x[2]),
    min_samples_leaf=int(otimos_dt.x[3]),
    max_features=otimos_dt.x[4],
    ccp_alpha=otimos_dt.x[5],
    random_state=0
)

# Certifique-se de que y_pred esteja definido para confusion_matrix

model_dt.fit(X_train_sc, y_train)
y_pred = model_dt.predict(X_train_sc)

mc = confusion_matrix(y_train, y_pred)
score = model_dt.score(X_train_sc, y_train)


plt.figure(figsize=(8, 6))
sns.heatmap(mc, annot=True, fmt='d', cmap='Reds', cbar=False,
            xticklabels=['Não Sobreviveu', 'Sobreviveu'],
            yticklabels=['Não Sobreviveu', 'Sobreviveu'])
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.title(f'Matriz de Confusão do Modelo Decision Tree (Acurácia: {score:.4f})')
plt.show()

#%% Otimização de hiperparâmetros para Naive Bayes
from skopt import gp_minimize
from sklearn.naive_bayes import GaussianNB

def treinar_modelo_nb(parametros):
    model_nb = GaussianNB(
        var_smoothing=parametros[0]  # Único hiperparâmetro relevante para GaussianNB
    )

    # Validação cruzada (10 folds)
    score = cross_val_score(model_nb, X_train_sc, y_train, cv=10, scoring='accuracy')
    mean_score = np.mean(score)
    print(f"Acurácia média: {mean_score:.4f}")

    return -mean_score  # Minimizar o negativo da acurácia

# Espaço de busca para o hiperparâmetro
parametros_nb = [
    (1e-11, 1e-1)  # var_smoothing (valores típicos: 1e-9 a 1e-3)
]

# Otimização Bayesiana
otimos_nb = gp_minimize(
    treinar_modelo_nb,
    parametros_nb,
    random_state=0,
    verbose=1,
    n_calls=20,
    n_random_starts=5
)

# Resultados
print(f"Melhor acurácia: {-otimos_nb.fun:.4f}")
print(f"Melhor var_smoothing: {otimos_nb.x[0]:.2e}")

model_nb = GaussianNB(var_smoothing=otimos_nb.x[0])

# Certifique-se de que y_pred esteja definido para confusion_matrix

model_nb.fit(X_train_sc, y_train)
y_pred = model_nb.predict(X_train_sc)

mc = confusion_matrix(y_train, y_pred)
score = model_nb.score(X_train_sc, y_train)

plt.figure(figsize=(8, 6))
sns.heatmap(mc, annot=True, fmt='d', cmap='Reds', cbar=False,
            xticklabels=['Não Sobreviveu', 'Sobreviveu'],
            yticklabels=['Não Sobreviveu', 'Sobreviveu'])
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.title(f'Matriz de Confusão do Modelo Naive Bayes (Acurácia: {score:.4f})')
plt.show()

#%% Otimização de hiperparâmetros para KNN:

model_knn = KNeighborsClassifier(
    n_neighbors=5,            # Valor ajustado para o padrão de dados
    weights='distance',       # Peso por proximidade (ideal para StandardScaler)
    p=1,                      # Distância de Manhattan (com StandardScaler)
    metric='minkowski'        # Combina com p=1 ou p=2
)
scores = cross_val_score(model_knn, X_train_sc, y_train, cv=10, scoring='accuracy')

print(f"Acurácia média (CV): {np.mean(scores):.4f} (±{np.std(scores):.4f})")

# 2. Otimização de hiperparâmetros com GridSearchCV
param_grid = {
    'n_neighbors': range(3, 15),
    'weights': ['uniform', 'distance'],
    'p': [1, 2]  # 1: Manhattan, 2: Euclidiana
}
grid_search = GridSearchCV(
    KNeighborsClassifier(),
    param_grid,
    cv=10,
    scoring='accuracy',
    n_jobs=-1
)
grid_search.fit(X_train_sc, y_train)

print(f"Melhores parâmetros: {grid_search.best_params_}")
print(f"Melhor acurácia (CV): {grid_search.best_score_:.4f}")

print(grid_search.best_params_)

# Use the best parameters found by GridSearchCV
best_params = grid_search.best_params_
model_knn = KNeighborsClassifier(n_neighbors=best_params['n_neighbors'],
                                 p=best_params['p'],
                                 weights=best_params['weights'])

# 2. Treinar com dados escalonados (X_train_sc)
model_knn.fit(X_train_sc, y_train)

# 3. Prever e avaliar
y_pred = model_knn.predict(X_train_sc)  # For internal validation

# Calculate confusion matrix and accuracy score
mc = confusion_matrix(y_train, y_pred)
accuracy = accuracy_score(y_train, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(mc, annot=True, fmt='d', cmap='Reds', cbar=False,
            xticklabels=['Não Sobreviveu', 'Sobreviveu'],
            yticklabels=['Não Sobreviveu', 'Sobreviveu'])
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.title(f'Matriz de Confusão do Modelo KNN (Acurácia: {accuracy:.4f})') # Use the calculated accuracy
plt.show()

"""#Ensamble Voting - Análise das respostas de cada modelo otimizado e a validação cruzada."""

# Analise previsões incertas
#%% Ensanble model (Voting)
from sklearn.ensemble import VotingClassifier
from sklearn.metrics import classification_report

#model_voting = VotingClassifier(estimators = [('LR', model_lr), ('KNN', model_knn), ('SVC', model_svc), ('RF', model_rf), ('XB', model_xgb)], voting = 'soft')

# SUBSTITUA seu model_voting atual por:
model_voting = VotingClassifier(
    estimators=[('LR', model_lr), ('KNN', model_knn),
               ('SVC', model_svc), ('RF', model_rf), ('XB', model_xgb)],
    voting='soft',  # Mude para soft
    weights=[0.1, 0.1, 0.3, 0.2, 0.3]  # pesos otimizados
)
model_voting.fit(X_train_sc, y_train)

probas = model_voting.predict_proba(X_train_sc)
uncertain_indices = np.where((probas.max(axis=1) > 0.45) & (probas.max(axis=1) < 0.55))[0]

print(f"\nPassageiros com previsões incertas ({len(uncertain_indices)}):")
uncertain_data = train.iloc[uncertain_indices][['Pclass', 'Sex', 'Age', 'Fare', 'SibSp', 'Parch', 'Survived']]
print(uncertain_data.describe())


# Generate predictions on the training data using the voting model
y_pred_train = model_voting.predict(X_train_sc)

mc = confusion_matrix(y_train, y_pred_train)
print(classification_report(y_train, y_pred_train))

score = cross_val_score(model_voting, X_train_sc, y_train, cv = 10)
print(np.mean(score))

plt.figure(figsize=(8, 6))
sns.heatmap(mc, annot=True, fmt='d', cmap='Reds', cbar=False,
            xticklabels=['Não Sobreviveu', 'Sobreviveu'],
            yticklabels=['Não Sobreviveu', 'Sobreviveu'])
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.title(f'Matriz de Confusão (Acurácia: {np.mean(score):.4f})')
plt.show()

# ===== ADICIONE VALIDAÇÃO ESTRATIFICADA =====
# Use StratifiedKFold para validação mais robusta
skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)

# Exemplo: para o modelo voting
voting_scores = cross_val_score(model_voting, X_train_sc, y_train, cv=skf, scoring='accuracy')
print(f"Validação Cruzada Estratificada - VotingClassifier: {np.mean(voting_scores):.4f} (±{np.std(voting_scores):.4f})")

plt.figure(figsize=(8, 6))
sns.heatmap(mc, annot=True, fmt='d', cmap='Reds', cbar=False,
            xticklabels=['Não Sobreviveu', 'Sobreviveu'],
            yticklabels=['Não Sobreviveu', 'Sobreviveu'])
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.title(f'Matriz de Confusão (Acurácia: {np.mean(voting_scores):.4f})')
plt.show()

# ===== ADICIONE ISSO ANTES DE GERAR O CSV =====
def post_process_predictions(predictions, original_data):
    """
    Aplica regras de pós-processamento baseadas em insights do dataset Titanic
    """
    final_predictions = predictions.copy()

    # Recrie as features necessárias para o pós-processamento usando original_data
    original_data = original_data.copy()
    original_data['mulher'] = original_data['Sex'].map({'female': 1, 'male': 0}).fillna(0)
    original_data['Age'] = original_data['Age'].fillna(original_data['Age'].mean())

    # Ensure original_data has the same index as predictions for correct boolean indexing
    original_data = original_data.set_index(predictions.index)


    # Regra 1: Mulheres na 1ª classe quase sempre sobreviveram
    women_class1 = (original_data['Pclass'] == 1) & (original_data['mulher'] == 1)
    final_predictions[women_class1] = 1

    # Regra 2: Homens na 3ª classe com mais de 15 anos quase sempre morreram
    men_class3 = (original_data['Pclass'] == 3) & (original_data['mulher'] == 0) & (original_data['Age'] > 15)
    final_predictions[men_class3] = 0

    # Regra 3: Crianças na 1ª e 2ª classes tendem a sobreviver
    children = (original_data['Age'] < 12) & (original_data['Pclass'].isin([1, 2]))
    final_predictions[children] = 1

    return final_predictions

# Get predictions on the test data first
y_pred_test = model_voting.predict(X_test_sc) # Or use model_stacking.predict(X_test_sc)

# Aplique o pós-processamento usando as predições no test set e o dataframe test original
y_pred_processed = post_process_predictions(pd.Series(y_pred_test), test) # Pass predictions as a pandas Series

# Use as previsões processadas para a submissão
submission = pd.DataFrame(test['PassengerId'])
submission['Survived'] = y_pred_processed  # Use as previsões processadas

# ===== ANÁLISE DOS PASSAGEIROS CRÍTICOS =====
# Passageiros que variaram entre suas submissões de 0.77272 e 0.78708
critical_passengers = [893, 928, 965, 979, 1023, 1073, 1094, 1134, 1160, 1200, 1297]

print("\nAnálise dos passageiros críticos:")
for passenger_id in critical_passengers:
    if passenger_id in test['PassengerId'].values:
        idx = test[test['PassengerId'] == passenger_id].index[0]
        print(f"Passageiro {passenger_id}:")
        print(f"  Classe: {test.loc[idx, 'Pclass']}")
        print(f"  Sexo: {test.loc[idx, 'Sex']}")
        print(f"  Idade: {test.loc[idx, 'Age']}")
        print(f"  Tarifa: {test.loc[idx, 'Fare']}")
        print(f"  Previsão: {y_pred[idx]}")
        print("---")

#%% predição nos dados de teste

y_pred = model_voting.predict(X_test_sc)

submission = pd.DataFrame(test['PassengerId'])

submission['Survived'] = y_pred

submission.to_csv('submission_new_classified.csv', index = False)

"""#Stacking em vez de Voting"""

from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression

# Defina os estimadores base
estimators = [
    ('xgb', model_xgb),
    ('rf', model_rf),
    ('svm', model_svc),
    ('knn', model_knn),
    ('lr', model_lr)
]

# Use Logistic Regression como meta-classificador
model_stacking = StackingClassifier(
    estimators=estimators,
    final_estimator=LogisticRegression(C=0.1, max_iter=1000),
    cv=5,
    stack_method='predict_proba'
)

# Fit the model to the training data
model_stacking.fit(X_train_sc, y_train)

#%% predição nos dados de teste

y_pred = model_stacking.predict(X_test_sc)

submission = pd.DataFrame(test['PassengerId'])

submission['Survived'] = y_pred

submission.to_csv('submission_stacking_voting_new_classifieds.csv', index = False)

"""#Blending com Pesos Otimizados"""

# Em vez de voting 'hard', use weighted blending
from sklearn.ensemble import VotingClassifier

# Defina pesos baseados no desempenho de cada modelo
model_weights = {
    'xgb': 0.35,
    'rf': 0.25,
    'svc': 0.20,
    'knn': 0.10,
    'lr': 0.10
}

model_voting = VotingClassifier(
    estimators=[('xgb', model_xgb), ('rf', model_rf),
               ('svc', model_svc), ('knn', model_knn), ('lr', model_lr)],
    voting='soft',
    weights=[model_weights['xgb'], model_weights['rf'],
            model_weights['svc'], model_weights['knn'], model_weights['lr']]
)

#%% predição nos dados de teste

model_voting.fit(X_train_sc, y_train)

y_pred = model_voting.predict(X_test_sc)

submission = pd.DataFrame(test['PassengerId'])

submission['Survived'] = y_pred

submission.to_csv('submission_stacking_voting_new_classifieds.csv', index = False)